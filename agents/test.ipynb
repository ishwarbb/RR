{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "from langchain_community.agent_toolkits.github.toolkit import GitHubToolkit\n",
    "from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class GitHubRepoSetup:\n",
    "    def __init__(self, repo_url, target_directory=None):\n",
    "        \"\"\"\n",
    "        Initialize GitHub repository setup\n",
    "        \n",
    "        Args:\n",
    "            repo_url (str): URL of the GitHub repository\n",
    "            target_directory (str, optional): Directory to clone repository. \n",
    "                                              Defaults to a temporary directory.\n",
    "        \"\"\"\n",
    "        self.repo_url = repo_url\n",
    "        self.target_directory = target_directory or tempfile.mkdtemp()\n",
    "        \n",
    "        # Initialize GitHub toolkit (optional, for additional GitHub interactions)\n",
    "        github = GitHubAPIWrapper()\n",
    "        self.toolkit = GitHubToolkit.from_github_api_wrapper(github)\n",
    "        \n",
    "        # Initialize language model\n",
    "        self.llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
    "\n",
    "    def clone_repository(self):\n",
    "        \"\"\"\n",
    "        Clone the GitHub repository to the target directory\n",
    "        \"\"\"\n",
    "        try:\n",
    "            subprocess.run([\n",
    "                'git', 'clone', self.repo_url, self.target_directory\n",
    "            ], check=True)\n",
    "            print(f\"Repository cloned to: {self.target_directory}\")\n",
    "            return self.target_directory\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error cloning repository: {e}\")\n",
    "            return None\n",
    "\n",
    "    def detect_project_type(self):\n",
    "        \"\"\"\n",
    "        Detect the type of project based on existing files\n",
    "        \"\"\"\n",
    "        project_indicators = {\n",
    "            'Python': ['requirements.txt', 'pyproject.toml', 'setup.py'],\n",
    "            'Node.js': ['package.json'],\n",
    "            'Java': ['pom.xml', 'build.gradle'],\n",
    "            'Ruby': ['Gemfile'],\n",
    "            'Rust': ['Cargo.toml']\n",
    "        }\n",
    "\n",
    "        for lang, files in project_indicators.items():\n",
    "            for file in files:\n",
    "                if os.path.exists(os.path.join(self.target_directory, file)):\n",
    "                    return lang\n",
    "        \n",
    "        return 'Unknown'\n",
    "\n",
    "    def setup_virtual_environment(self, project_type):\n",
    "        \"\"\"\n",
    "        Set up a virtual environment based on project type\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if project_type == 'Python':\n",
    "                # Create Python virtual environment\n",
    "                subprocess.run([\n",
    "                    'python3', '-m', 'venv', \n",
    "                    os.path.join(self.target_directory, 'venv')\n",
    "                ], check=True)\n",
    "                \n",
    "                # Activate virtual environment and install dependencies\n",
    "                venv_python = os.path.join(self.target_directory, 'venv', 'bin', 'python')\n",
    "                venv_pip = os.path.join(self.target_directory, 'venv', 'bin', 'pip')\n",
    "                \n",
    "                # Check for different dependency files\n",
    "                if os.path.exists(os.path.join(self.target_directory, 'requirements.txt')):\n",
    "                    subprocess.run([\n",
    "                        venv_pip, 'install', \n",
    "                        '-r', os.path.join(self.target_directory, 'requirements.txt')\n",
    "                    ], check=True)\n",
    "                elif os.path.exists(os.path.join(self.target_directory, 'pyproject.toml')):\n",
    "                    subprocess.run([\n",
    "                        venv_pip, 'install', 'poetry'\n",
    "                    ], check=True)\n",
    "                    subprocess.run([\n",
    "                        'poetry', 'install'\n",
    "                    ], cwd=self.target_directory, check=True)\n",
    "            \n",
    "            elif project_type == 'Node.js':\n",
    "                # Use nvm to manage Node.js version\n",
    "                subprocess.run([\n",
    "                    'npm', 'install'\n",
    "                ], cwd=self.target_directory, check=True)\n",
    "            \n",
    "            print(f\"Virtual environment and dependencies set up for {project_type} project\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple code executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_experimental\n",
      "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain_experimental)\n",
      "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.28 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain_experimental) (0.3.44)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.20)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.11.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (9.0.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.13)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.10.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.20->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.6)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.14.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/victorknox/miniconda3/envs/nlp/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
      "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
      "Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community, langchain_experimental\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.19 langchain_experimental-0.3.4 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_experimental \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage, \n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from tenacity import retry, stop_after_attempt\n",
    "import json\n",
    "\n",
    "# Initialize Python REPL\n",
    "repl = PythonREPL()\n",
    "\n",
    "@tool\n",
    "@retry(stop=stop_after_attempt(3))\n",
    "def python_repl(\n",
    "    code: str,\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\n",
    "    Always give the code in the required JSON format.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = f\"\\nSuccessfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )\n",
    "\n",
    "class CodeExecutionAgent:\n",
    "    def __init__(self, base_url=\"http://your-api-url\", api_key=\"your-api-key\"):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0,\n",
    "            base_url=base_url,\n",
    "            api_key=api_key\n",
    "        )\n",
    "        \n",
    "        # Create the prompt template\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are a helpful AI assistant that can execute Python code. \"\n",
    "                      \"Use the python_repl tool to execute code and help solve problems. \"\n",
    "                      \"Always show your thinking process and explain what the code does.\"),\n",
    "            MessagesPlaceholder(variable_name=\"messages\")\n",
    "        ])\n",
    "        \n",
    "        # Create the chain\n",
    "        self.agent = self.prompt | self.llm.bind_tools([python_repl])\n",
    "    \n",
    "    def run(self, query: str):\n",
    "        \"\"\"Run a query through the agent\"\"\"\n",
    "        messages = [HumanMessage(content=query)]\n",
    "        response = self.agent.invoke({\"messages\": messages})\n",
    "        return response.content\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    agent = CodeExecutionAgent(api_key=\"api-key\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"Enter your question (or 'exit' to quit): \")\n",
    "        if query.lower() == 'exit':\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            response = agent.run(query)\n",
    "            print(\"\\nResponse:\", response)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we initialize the model we want to use.\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage, \n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from tenacity import retry, stop_after_attempt\n",
    "import json\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0, api_key=\"api_key\")\n",
    "\n",
    "# For this tutorial we will use custom tool that returns pre-defined values for weather in two cities (NYC & SF)\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# Initialize Python REPL\n",
    "repl = PythonREPL()\n",
    "\n",
    "@tool\n",
    "@retry(stop=stop_after_attempt(3))\n",
    "def python_repl(\n",
    "    code: str,\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\n",
    "    Always give the code in the required JSON format.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = f\"\\nSuccessfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )\n",
    "\n",
    "tools = [python_repl]\n",
    "\n",
    "\n",
    "# Define the graph\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "graph = create_react_agent(model, tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Run code to calculate 8 + 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  python_repl (call_KsFlmkWkkdZfoIBgLShK181t)\n",
      " Call ID: call_KsFlmkWkkdZfoIBgLShK181t\n",
      "  Args:\n",
      "    code: print(8 + 6)\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: python_repl\n",
      "\n",
      "\n",
      "Successfully executed:\n",
      "```python\n",
      "print(8 + 6)\n",
      "```\n",
      "Stdout: 14\n",
      "\n",
      "\n",
      "If you have completed all tasks, respond with FINAL ANSWER.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of 8 + 6 is 14.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [(\"user\", \"Run code to calculate 8 + 6\")]}\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
